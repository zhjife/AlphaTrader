import streamlit as st
import akshare as ak
import pandas as pd
import numpy as np
from snownlp import SnowNLP
from datetime import datetime, timedelta
import warnings
import io
from concurrent.futures import ThreadPoolExecutor

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="Alpha Galaxy æé€Ÿç‰ˆ", layout="wide")

# ================= 0. ç¼“å­˜åŠ é€Ÿå±‚ (æ–°å¢ä¼˜åŒ–) =================
# åŠ ä¸Šè¿™ä¸ªè£…é¥°å™¨ï¼ŒStreamlit ä¼šæŠŠç»“æœå­˜èµ·æ¥ï¼Œé»˜è®¤ 5 åˆ†é’Ÿ(300ç§’)å†…ä¸å†é‡å¤ä¸‹è½½å…¨å¸‚åœºæ•°æ®
# è¿™æ ·åˆ‡æ¢ä¸åŒè‚¡ç¥¨æ—¶ï¼Œé€Ÿåº¦ä¼šé£å¿«
@st.cache_data(ttl=300)
def get_market_spot_data():
    try:
        return ak.stock_zh_a_spot_em()
    except:
        return pd.DataFrame()

# ================= æ ¸å¿ƒç±»å®šä¹‰ =================
class AlphaGalaxyUltimate:
    def __init__(self, symbol):
        self.symbol = str(symbol)
        self.data = {}
        self.report = {
            "verdict": "è§‚æœ›", "risk_level": "ä¸­", 
            "score": 0, "mode": "éœ‡è¡", "kelly_pos": 0, 
            "logic": [], "signals": [],
            "patterns_bull": [], "patterns_bear": []
        }
        self.metrics = []
        self.levels = []
        self.history_metrics = {}
        
        # æŒ‡æ•°æ˜ å°„
        if self.symbol.startswith('6'): self.index_name = "ä¸Šè¯æŒ‡æ•°"
        elif self.symbol.startswith('8') or self.symbol.startswith('4'): self.index_name = "åŒ—è¯50"
        else: self.index_name = "æ·±è¯æˆæŒ‡"

    # ================= 1. æ•°æ®ä¸­å° (æ”¹ä¸ºå¤šçº¿ç¨‹å¹¶è¡Œ) =================
    def _fetch_data_parallel(self):
        st.toast(f"ğŸš€ [æé€Ÿæ‰«æ] æ­£åœ¨å¹¶å‘è¯»å– {self.symbol} ...")
        
        # å®šä¹‰ç‹¬ç«‹çš„ä»»åŠ¡å‡½æ•°
        def task_hist():
            try:
                end = datetime.now().strftime("%Y%m%d")
                start = (datetime.now() - timedelta(days=730)).strftime("%Y%m%d")
                # å°è¯•è¯»å–
                df = ak.stock_zh_a_hist(symbol=self.symbol, period='daily', start_date=start, end_date=end, adjust='qfq')
                if df is not None and not df.empty:
                    df.rename(columns={'æ—¥æœŸ':'date', 'å¼€ç›˜':'open', 'æ”¶ç›˜':'close', 'æœ€é«˜':'high', 'æœ€ä½':'low', 'æˆäº¤é‡':'volume', 'æ¢æ‰‹ç‡':'turnover'}, inplace=True)
                    return df
            except: pass
            return None

        def task_flow():
            try:
                mkt = "sh" if self.symbol.startswith("6") else "sz"
                flow = ak.stock_individual_fund_flow(stock=self.symbol, market=mkt)
                if flow is not None and not flow.empty:
                    return flow.sort_values('æ—¥æœŸ').tail(10)
            except: pass
            return pd.DataFrame()

        def task_news():
            try:
                return ak.stock_news_em(symbol=self.symbol)
            except: return pd.DataFrame()

        # --- æ ¸å¿ƒä¼˜åŒ–ï¼šä½¿ç”¨çº¿ç¨‹æ± åŒæ—¶è¿è¡Œ ---
        with ThreadPoolExecutor(max_workers=3) as executor:
            # 1. å®æ—¶è¡Œæƒ… (åˆ©ç”¨ç¼“å­˜ï¼Œæå¿«)
            # æ³¨æ„ï¼šå®æ—¶è¡Œæƒ…ä¸æ”¾å…¥çº¿ç¨‹æ± ï¼Œå› ä¸ºæˆ‘ä»¬è¦åˆ©ç”¨ Streamlit çš„å…¨å±€ç¼“å­˜
            try:
                full_spot = get_market_spot_data()
                target = full_spot[full_spot['ä»£ç '] == self.symbol]
                if not target.empty:
                    target = target.copy()
                    for col in ['å¸‚ç›ˆç‡-åŠ¨æ€', 'å¸‚å‡€ç‡', 'æ€»å¸‚å€¼', 'æ¢æ‰‹ç‡', 'æœ€æ–°ä»·']:
                        if col in target.columns:
                            target[col] = pd.to_numeric(target[col], errors='coerce')
                    self.data['spot'] = target.iloc[0]
                else:
                    self.data['spot'] = {'åç§°': self.symbol, 'æœ€æ–°ä»·': 0, 'å¸‚ç›ˆç‡-åŠ¨æ€': -1, 'å¸‚å‡€ç‡': -1, 'æ¢æ‰‹ç‡': 0}
            except:
                self.data['spot'] = {'åç§°': self.symbol, 'å¸‚ç›ˆç‡-åŠ¨æ€': -1, 'å¸‚å‡€ç‡': -1}

            # 2. å¹¶è¡Œå‘èµ·ç½‘ç»œè¯·æ±‚ (Hist, Flow, News)
            future_hist = executor.submit(task_hist)
            future_flow = executor.submit(task_flow)
            future_news = executor.submit(task_news)

            # 3. è·å–ç»“æœ
            self.data['hist'] = future_hist.result()
            self.data['flow'] = future_flow.result()
            self.data['news'] = future_news.result()

        # æ£€æŸ¥å…³é”®æ•°æ®
        if self.data['hist'] is None:
            st.error(f"âŒ æ— æ³•è·å– K çº¿æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»£ç  {self.symbol} æ˜¯å¦æ­£ç¡®ã€‚")
            return False

        # æ•°æ®è¡¥å…¨
        if self.data['spot'].get('æœ€æ–°ä»·', 0) == 0: 
            self.data['spot']['æœ€æ–°ä»·'] = self.data['hist'].iloc[-1]['close']
        if self.data['spot'].get('æ¢æ‰‹ç‡', 0) == 0 and 'turnover' in self.data['hist'].columns:
            self.data['spot']['æ¢æ‰‹ç‡'] = self.data['hist'].iloc[-1]['turnover']

        return True

    # ================= 2. èˆ†æƒ…åˆ†æå¼•æ“ =================
    def _analyze_sentiment(self):
        try:
            if self.data['news'].empty: return 0, "æ— è¿‘æœŸèˆ†æƒ…"
            news_df = self.data['news'].head(10)
            titles = news_df['æ–°é—»æ ‡é¢˜'].tolist()
            full_text = "ã€‚".join(titles)
            
            pos_kw = ['å¢é•¿', 'é¢„å¢', 'çªç ´', 'åˆ©å¥½', 'å›è´­', 'è·æ‰¹', 'ä¸­æ ‡', 'å¤§æ¶¨', 'æ–°é«˜']
            neg_kw = ['ç«‹æ¡ˆ', 'è°ƒæŸ¥', 'äºæŸ', 'å‡æŒ', 'è­¦ç¤º', 'è¿è§„', 'å¤§è·Œ', 'é€€å¸‚', 'è¢«æŸ¥']
            
            hard_score = 0
            keywords = []
            for t in titles:
                for kw in pos_kw:
                    if kw in t: hard_score += 2; keywords.append(kw)
                for kw in neg_kw:
                    if kw in t: hard_score -= 10; keywords.append(kw)
            
            s = SnowNLP(full_text)
            soft_score = (s.sentiments - 0.5) * 10
            total = max(min(hard_score + soft_score, 20), -20)
            return round(total, 1), f"å…³é”®è¯:{list(set(keywords))}" if keywords else "èˆ†æƒ…å¹³ç¨³"
        except: return 0, "èˆ†æƒ…åˆ†æç•¥è¿‡"

    # ================= 3. æŒ‡æ ‡è®¡ç®— =================
    def _calc_indicators(self, df):
        # MA
        for w in [5, 10, 20, 60, 120, 250]: df[f'ma{w}'] = df['close'].rolling(w).mean()
        
        # MACD
        ema12 = df['close'].ewm(span=12, adjust=False).mean()
        ema26 = df['close'].ewm(span=26, adjust=False).mean()
        df['dif'] = ema12 - ema26
        df['dea'] = df['dif'].ewm(span=9, adjust=False).mean()
        
        # KDJ
        low_9 = df['low'].rolling(9).min(); high_9 = df['high'].rolling(9).max()
        rsv = (df['close'] - low_9) / (high_9 - low_9) * 100
        df['k'] = rsv.ewm(com=2, adjust=False).mean()
        df['d'] = df['k'].ewm(com=2, adjust=False).mean()
        df['j'] = 3 * df['k'] - 2 * df['d']
        
        # RSI (Wilder)
        delta = df['close'].diff()
        up = delta.clip(lower=0); down = -1 * delta.clip(upper=0)
        for period in [6, 12, 24]:
            ema_up = up.ewm(alpha=1/period, adjust=False).mean()
            ema_down = down.ewm(alpha=1/period, adjust=False).mean()
            rs = ema_up / ema_down
            df[f'rsi_{period}'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi_6'] 
        
        # BOLL
        df['std'] = df['close'].rolling(20).std()
        df['up'] = df['ma20'] + 2 * df['std']
        df['dn'] = df['ma20'] - 2 * df['std']
        df['bb_width'] = (df['up'] - df['dn']) / df['ma20'] 
        
        # ATR & Drawdown
        df['tr'] = np.maximum(df['high'] - df['low'], abs(df['high'] - df['close'].shift(1)))
        df['atr'] = df['tr'].ewm(alpha=1/14, adjust=False).mean()
        roll_max = df['close'].rolling(250, min_periods=1).max()
        df['drawdown'] = (df['close'] / roll_max) - 1.0

        # ADX & CCI & BIAS
        up_move = df['high'] - df['high'].shift(1); down_move = df['low'].shift(1) - df['low']
        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)
        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)
        tr_smooth = df['tr'].ewm(alpha=1/14, adjust=False).mean()
        plus_di = 100 * (pd.Series(plus_dm).ewm(alpha=1/14, adjust=False).mean() / tr_smooth)
        minus_di = 100 * (pd.Series(minus_dm).ewm(alpha=1/14, adjust=False).mean() / tr_smooth)
        dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
        df['adx'] = dx.ewm(alpha=1/14, adjust=False).mean()

        tp = (df['high'] + df['low'] + df['close']) / 3
        df['cci'] = (tp - tp.rolling(14).mean()) / (0.015 * tp.rolling(14).apply(lambda x: np.mean(np.abs(x - np.mean(x))), raw=True))
        df['bias'] = (df['close'] - df['ma20']) / df['ma20'] * 100
        
        # CMF & Vol Ratio & PCT
        df['obv'] = (np.sign(df['close'].diff()) * df['volume']).fillna(0).cumsum()
        mf_mult = ((df['close'] - df['low']) - (df['high'] - df['close'])) / (df['high'] - df['low']).replace(0, 0.01)
        df['cmf'] = (mf_mult * df['volume']).rolling(20).sum() / df['volume'].rolling(20).sum()
        df['vol_ma5'] = df['volume'].rolling(5).mean().shift(1)
        df['vol_ratio'] = df['volume'] / df['vol_ma5']
        df['pct_change'] = df['close'].pct_change() * 100
        
        return df

    # ================= 4. ç­¹ç è·åˆ©ç›˜ =================
    def _calc_chip_winner(self, df):
        if len(df) < 120: return 50
        sub = df.tail(60).copy()
        current_price = df['close'].iloc[-1]
        sub['avg_price'] = (sub['open'] + sub['close'] + sub['high'] + sub['low']) / 4
        winner_vol = sub[sub['avg_price'] < current_price]['volume'].sum()
        total_vol = sub['volume'].sum()
        if total_vol == 0: return 0
        return (winner_vol / total_vol) * 100

    # ================= 5. Kçº¿å½¢æ€è¯†åˆ« (å…¨é‡ä¿ç•™) =================
    def _analyze_pattern_full(self, df):
        if len(df) < 20: return [], [], 0
        bull_pats, bear_pats = [], []
        score = 0 
        
        c = df['close'].values; o = df['open'].values
        h = df['high'].values; l = df['low'].values
        v = df['volume'].values
        ma5 = df['ma5'].values; ma10 = df['ma10'].values; ma20 = df['ma20'].values
        
        c0, c1, c2, c3, c4 = c[-1], c[-2], c[-3], c[-4], c[-5]
        o0, o1, o2, o3, o4 = o[-1], o[-2], o[-3], o[-4], o[-5]
        h0, h1 = h[-1], h[-2]; l0, l1 = l[-1], l[-2]
        v0, v1 = v[-1], v[-2]
        
        body0 = abs(c0 - o0)
        upper0 = h0 - max(c0, o0); lower0 = min(c0, o0) - l0
        is_bull0 = c0 > o0; is_bear0 = c0 < o0
        is_downtrend = c0 < ma20[-1]; is_uptrend = c0 > ma20[-1]

        # [ä¹°å…¥]
        if c2 < o2 and is_bear0 is False and abs(c1-o1) < body0*0.5 and c0 > (o2+c2)/2: bull_pats.append("æ—©æ™¨ä¹‹æ˜Ÿ"); score += 20
        if is_downtrend and lower0 > 2*body0 and upper0 < body0*0.2: bull_pats.append("é”¤å­çº¿"); score += 15
        if is_downtrend and upper0 > 2*body0 and lower0 < body0*0.2: bull_pats.append("å€’é”¤å¤´"); score += 10
        if c1 < o1 and is_bull0 and c0 > o1 and o0 < c1: bull_pats.append("é˜³åŒ…é˜´"); score += 20
        if c1 < o1 and is_bull0 and o0 < l1 and c0 > (o1+c1)/2 and c0 < o1: bull_pats.append("æ›™å…‰åˆç°"); score += 15
        if is_downtrend and abs(l0 - l1) < c0*0.002: bull_pats.append("å¹³åº•"); score += 10
        if c1 < o1 and is_bull0 and h0 < h1 and l0 > l1: bull_pats.append("å¤šå¤´å­•çº¿"); score += 10
        if c0>o0 and c1>o1 and c2>o2 and c0>c1>c2: bull_pats.append("çº¢ä¸‰å…µ"); score += 15
        if c4>o4 and c0>o0 and c0>c4 and c1<o1 and c2<o2: bull_pats.append("ä¸Šå‡ä¸‰æ³•"); score += 20
        if c2>o2 and c1<o1 and c0>o0 and c0>c2 and o1<c2: bull_pats.append("å¤šæ–¹ç‚®"); score += 20
        if l0 > h1: bull_pats.append("å‘ä¸Šç¼ºå£"); score += 15
        if is_bull0 and c0 > max(ma5[-1], ma10[-1], ma20[-1]) and o0 < min(ma5[-1], ma10[-1], ma20[-1]): bull_pats.append("ä¸€é˜³ç©¿ä¸‰çº¿"); score += 25
        if v0 > v1*1.9 and c0 > np.max(c[-20:-1]): bull_pats.append("å€é‡è¿‡å·¦å³°"); score += 20
        diff = max(ma5[-1],ma10[-1],ma20[-1]) - min(ma5[-1],ma10[-1],ma20[-1])
        if (diff/c0 < 0.015) and is_bull0: bull_pats.append("é‡‘èœ˜è››"); score += 15
        if (h1-max(c1,o1)) > abs(c1-o1) and c0>h1 and is_bull0: bull_pats.append("ä»™äººæŒ‡è·¯"); score += 15
        if c1 < o1 and is_bull0 and o0 > c1 and c0 > o1: bull_pats.append("æ—­æ—¥ä¸œå‡"); score += 20
        if h[-2] < l[-3] and l[-1] > h[-2]: bull_pats.append("å²›å½¢åè½¬(åº•)"); score += 30
        if c1 < o1 and is_bull0 and o0 > h1: bull_pats.append("è¸¢è„šçº¿"); score += 30
        if l0 <= ma20[-1] and c0 > ma20[-1] and c1 > ma20[-1] and is_bull0: bull_pats.append("èœ»èœ“ç‚¹æ°´"); score += 10

        # [å–å‡º]
        if c2 > o2 and abs(c1-o1) < body0*0.5 and is_bear0 and c0 < (o2+c2)/2: bear_pats.append("é»„æ˜ä¹‹æ˜Ÿ"); score -= 20
        if c1 > o1 and is_bear0 and o0 > h1 and c0 < (o1+c1)/2: bear_pats.append("ä¹Œäº‘ç›–é¡¶"); score -= 20
        if is_bear0 and o0 > max(ma5[-1],ma10[-1],ma20[-1]) and c0 < min(ma5[-1],ma10[-1],ma20[-1]): bear_pats.append("æ–­å¤´é“¡åˆ€"); score -= 30
        if c0<o0 and c1<o1 and c2<o2 and c0<c1<c2: bear_pats.append("ä¸‰åªä¹Œé¸¦"); score -= 25
        if h0 < l1: bear_pats.append("å‘ä¸‹ç¼ºå£"); score -= 15
        if c1 > o1 and is_bear0 and o0 > c1 and c0 < o1: bear_pats.append("é˜´åŒ…é˜³"); score -= 20
        if not is_downtrend and upper0 > 2*body0 and lower0 < body0*0.2: bear_pats.append("å°„å‡»ä¹‹æ˜Ÿ"); score -= 15
        if is_uptrend and lower0 > 2*body0 and upper0 < body0*0.2: bear_pats.append("åŠé¢ˆçº¿"); score -= 15
        if is_uptrend and abs(h0 - h1) < c0*0.002: bear_pats.append("å¹³é¡¶"); score -= 10
        if c1 > o1 and is_bear0 and o0 < c1 and c0 < o1: bear_pats.append("å€¾ç›†å¤§é›¨"); score -= 20
        if c1 > o1 and is_bear0 and h0 < h1 and l0 > l1: bear_pats.append("ç©ºå¤´å­•çº¿"); score -= 10
        if l[-2] > h[-3] and h[-1] < l[-2]: bear_pats.append("å²›å½¢åè½¬(é¡¶)"); score -= 30
        if upper0 > 2*body0 and abs(o0-c0) < 0.01*c0 and lower0 < 0.1*body0: bear_pats.append("å¢“ç¢‘çº¿"); score -= 20
        
        return bull_pats, bear_pats, score

    # ================= 6. æ ¸å¿ƒé€»è¾‘ =================
    def _check_combo_logic(self, curr, flow_val, sentiment_score, k_score, winner_pct):
        signals = []; reasons = []; score = 0
        priority_verdict = None 
        close = curr['close']
        
        # 1. åŸºç¡€æŠ€æœ¯
        if close > curr['ma20']: score += 20
        if curr['adx'] > 25: score += 10
        if curr['cci'] > 100: score += 10
        score += k_score + sentiment_score

        # 2. åŸºæœ¬é¢
        pe = self.data['spot'].get('å¸‚ç›ˆç‡-åŠ¨æ€', -1)
        pb = self.data['spot'].get('å¸‚å‡€ç‡', -1)
        if 0 < pe <= 20: score += 15; reasons.append(f"ğŸ’ [åŸºæœ¬é¢] ä½ä¼°å€¼(PE={pe})")
        elif pe < 0: score -= 10; reasons.append(f"âš ï¸ [åŸºæœ¬é¢] äºæŸè‚¡")
        if pb > 10: score -= 5; reasons.append(f"âš ï¸ [åŸºæœ¬é¢] é«˜å¸‚å‡€ç‡")

        # 3. é£æ§
        if curr.get('turnover', 0) > 15 and abs(curr['pct_change']) < 3: score -= 20; reasons.append("ğŸ’€ [é£æ§] é«˜æ¢æ‰‹æ»æ¶¨")
        if winner_pct > 95: score -= 10; reasons.append(f"âš ï¸ [ç­¹ç ] è·åˆ©ç›˜é«˜({int(winner_pct)}%)")
        elif winner_pct < 5: score += 10; reasons.append(f"ğŸ’° [ç­¹ç ] è·åˆ©ç›˜ä½({int(winner_pct)}%)")

        # 4. æˆ˜æ³•
        is_low = close < curr['ma60'] * 1.15
        if is_low and curr.get('turnover', 0) > 3 and curr['vol_ratio'] > 1.8:
            signals.append("ä¸»åŠ›å¯åŠ¨"); reasons.append("ğŸ”¥ [ç»„åˆA] ä½ä½æ”¾é‡å¯åŠ¨"); score += 15; priority_verdict = "ä¹°å…¥"
        elif close > curr['ma20'] and curr.get('turnover', 0) < 3 and 0.7 < curr['vol_ratio'] < 1.3:
            signals.append("ä¸»åŠ›é”ç­¹"); reasons.append("ğŸ”’ [ç»„åˆA] ç¼©é‡é”ç­¹"); score += 10
            if priority_verdict is None: priority_verdict = "æŒæœ‰"

        if curr['dif'] > curr['dea'] and curr['rsi'] > 80:
            signals.append("å‡ä¹°ç‚¹"); reasons.append("ğŸš« [ç»„åˆB] MACDé‡‘å‰ä½†RSIè¿‡çƒ­"); score -= 5
            if priority_verdict == "ä¹°å…¥": priority_verdict = "è§‚å¯Ÿ"
        
        if close < curr['dn'] and (flow_val > 0.5 or curr['cmf'] > 0.1):
            signals.append("é»„é‡‘å‘"); reasons.append("ğŸ’° [ç»„åˆC] è·Œç ´ä¸‹è½¨+èµ„é‡‘æµå…¥"); score += 20; priority_verdict = "ä½å¸"
            
        return signals, reasons, priority_verdict, score

    # ================= 7. ç»¼åˆåˆ†æä¸»æ§ =================
    def _analyze(self):
        df = self._calc_indicators(self.data['hist'].copy())
        winner_pct = self._calc_chip_winner(df)
        curr = df.iloc[-1]
        close = curr['close']
        
        flow_val = 0
        if not self.data['flow'].empty and 'ä¸»åŠ›å‡€æµå…¥å‡€é¢' in self.data['flow'].columns:
            try: flow_val = round(self.data['flow']['ä¸»åŠ›å‡€æµå…¥å‡€é¢'].iloc[-3:].sum() / 1e8, 2)
            except: pass
            
        s_score, s_msg = self._analyze_sentiment()
        bull_pats, bear_pats, k_score = self._analyze_pattern_full(df)
        combo_signals, combo_logic, combo_verdict, final_score = self._check_combo_logic(curr, flow_val, s_score, k_score, winner_pct)
        stop_price = close - 2 * curr['atr']
        
        verdict = "è§‚æœ›"; risk = "ä¸­"
        if s_score < -10: verdict = "é¿é™©å–å‡º"; risk = "æé«˜"
        elif close < stop_price: verdict = "æ¸…ä»“æ­¢æŸ"; risk = "æé«˜"; combo_logic.insert(0, f"âŒ [é£æ§] è·Œç ´ATRæ­¢æŸ")
        elif "æ–­å¤´é“¡åˆ€" in bear_pats or "ä¸‰åªä¹Œé¸¦" in bear_pats: verdict = "ç¦»åœº"; risk = "é«˜"; combo_logic.append(f"âŒ [Kçº¿] æ¶åŠ£å½¢æ€")
        elif combo_verdict: verdict = combo_verdict
        elif final_score >= 60: verdict = "ä¹°å…¥" if flow_val > 0 else "è§‚å¯Ÿ"; risk = "ä½" if flow_val > 0 else "ä¸­"
        elif final_score < 0: verdict = "å‡ä»“"; risk = "é«˜"

        risk = "é«˜" if verdict in ["æ¸…ä»“", "å–å‡º", "ç¦»åœº"] else risk
        base_pos = 60 if verdict in ["ä¹°å…¥", "æŒæœ‰", "ä¸»åŠ›é”ç­¹"] else 0
        if final_score > 80: base_pos = 80
        if "ä½å¸" in verdict: base_pos = 30
        
        curr_1 = df.iloc[-2]; curr_2 = df.iloc[-3]
        
        self.report.update({
            "verdict": verdict, "risk_level": risk, 
            "score": int(final_score), "kelly_pos": base_pos, 
            "logic": combo_logic, "signals": combo_signals,
            "patterns_bull": bull_pats, "patterns_bear": bear_pats
        })

        self._add_metric("æ ¸å¿ƒæŒ‡æ ‡", f"RSI:{int(curr['rsi'])}", f"ATR:{round(curr['atr'],2)}", "RSI>80è¿‡çƒ­", "-")
        self._add_metric("èµ„é‡‘ç­¹ç ", f"ä¸»åŠ›:{flow_val}äº¿", f"è·åˆ©ç›˜:{int(winner_pct)}%", "è·åˆ©>90%æœ‰é£é™©", "-")
        pe_val = self.data['spot'].get('å¸‚ç›ˆç‡-åŠ¨æ€','-')
        self._add_metric("åŸºæœ¬é¢/èˆ†æƒ…", f"PE:{pe_val}", f"èˆ†æƒ…:{s_score}", "PE<20ä½ä¼°", "-")
        
        self.history_metrics = {
            "pct_0": curr['pct_change'], "pct_1": curr_1['pct_change'], 
            "cmf_0": curr['cmf'], "cmf_1": curr_1['cmf']
        }
        
        # ç‚¹ä½
        ma20 = curr['ma20']; ma60 = curr['ma60']
        ma20_type = "ğŸŸ¢ MA20æ”¯æ’‘" if close > ma20 else "ğŸ”´ MA20å‹åŠ›"
        ma60_type = "ğŸŸ¢ ç”Ÿå‘½çº¿(MA60)" if close > ma60 else "ğŸ”´ ç”Ÿå‘½çº¿(MA60)"
        self.levels.append(["ğŸ”´ æ­¢æŸ(ATR)", round(stop_price, 2), "ç¡¬æ­¢æŸä½"])
        self.levels.append([ma20_type, round(ma20, 2), "è¶‹åŠ¿çº¿"])
        self.levels.append([ma60_type, round(ma60, 2), "ç‰›ç†Šåˆ†ç•Œ"])
        self.levels.append(["ğŸ”´ è¿‘æœŸç®±é¡¶", round(df['high'].tail(20).max(), 2), "20æ—¥æ–°é«˜"])
        self.levels.append(["ğŸŸ¢ è¿‘æœŸç®±åº•", round(df['low'].tail(20).min(), 2), "20æ—¥æ–°ä½"])
        
        return True

    def _add_metric(self, name, val1, val2, explanation, logic):
        self.metrics.append({"ç»´åº¦": name, "æ•°æ®1": val1, "æ•°æ®2": val2, "åˆ¤å®šé€»è¾‘": explanation})

    # === é€‚é… Web ä¸‹è½½ ===
    def generate_excel_in_memory(self):
        # æ¢ç”¨å¹¶è¡Œæ¥å£
        if not self._fetch_data_parallel(): return None, None
        self._analyze()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        spot_name = self.data['spot'].get('åç§°', self.symbol)
        filename = f"{self.symbol}_{spot_name}_æé€Ÿå¢å¼ºç‰ˆ_{timestamp}.xlsx"
        
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            s_data = [
                ["ä»£ç ", self.symbol], ["åç§°", spot_name],
                ["å»ºè®®", self.report['verdict']], ["æ€»åˆ†", self.report['score']],
                ["ä»“ä½", f"{self.report['kelly_pos']}%"], ["é£é™©", self.report['risk_level']],
                ["ç»„åˆæˆ˜æ³•", " | ".join(self.report['signals'])],
                ["", ""], ["å†³ç­–é€»è¾‘", "\n".join(self.report['logic'])]
            ]
            pd.DataFrame(s_data, columns=["é¡¹ç›®", "å†…å®¹"]).to_excel(writer, sheet_name='å†³ç­–çœ‹æ¿', index=False)
            
            metrics_df = pd.DataFrame(self.metrics)
            extra_rows = [
                {"ç»´åº¦":"æ¶¨è·Œå¹…å›é¡¾", "æ•°æ®1":f"ä»Š:{round(self.history_metrics['pct_0'],2)}%", "æ•°æ®2":f"æ˜¨:{round(self.history_metrics['pct_1'],2)}%", "åˆ¤å®šé€»è¾‘":"è¿‘æœŸèµ°åŠ¿"},
                {"ç»´åº¦":"èµ„é‡‘å›é¡¾", "æ•°æ®1":f"ä»Š:{round(self.history_metrics['cmf_0'],2)}", "æ•°æ®2":f"æ˜¨:{round(self.history_metrics['cmf_1'],2)}", "åˆ¤å®šé€»è¾‘":"CMFè¶‹åŠ¿"}
            ]
            metrics_df = pd.concat([metrics_df, pd.DataFrame(extra_rows)], ignore_index=True)
            metrics_df.to_excel(writer, sheet_name='è¯¦ç»†æŒ‡æ ‡', index=False)
            pd.DataFrame(self.levels, columns=["ç±»å‹", "ä»·æ ¼", "è¯´æ˜"]).to_excel(writer, sheet_name='ç‚¹ä½ç®¡ç†', index=False)
            
            # å½¢æ€å›¾è§£å­—å…¸
            patterns_desc = [
                ['å½¢æ€åç§°', 'ç±»å‹', 'å¤§ç™½è¯è¯´æ˜'],
                ['æ—©æ™¨ä¹‹æ˜Ÿ', 'ä¹°å…¥', 'åº•éƒ¨ä¸‰æ—¥ç»„åˆï¼šé˜´çº¿+æ˜Ÿçº¿+é˜³çº¿ï¼Œå¼ºåŠ›è§åº•'],
                ['é”¤å­çº¿', 'ä¹°å…¥', 'åº•éƒ¨é•¿ä¸‹å½±çº¿ï¼Œä¸»åŠ›è¯•ç›˜åæ‹‰å›ï¼Œæ”¯æ’‘å¼º'],
                ['å€’é”¤å¤´', 'ä¹°å…¥', 'åº•éƒ¨é•¿ä¸Šå½±çº¿ï¼Œä¸»åŠ›ä½ä½è¯•ç›˜ï¼ŒæŠ›å‹å‡è½»'],
                ['é˜³åŒ…é˜´', 'ä¹°å…¥', 'ä»Šæ—¥é˜³çº¿å®Œå…¨åŒ…ä½æ˜¨æ—¥é˜´çº¿ï¼Œå¤šå¤´åå‡»'],
                ['æ›™å…‰åˆç°', 'ä¹°å…¥', 'å¤§é˜´çº¿åä½å¼€é«˜èµ°ï¼Œé˜³çº¿åˆºå…¥é˜´çº¿ä¸€åŠ'],
                ['å¹³åº•', 'ä¹°å…¥', 'ä¸¤æ—¥æœ€ä½ä»·ç›¸åŒï¼Œç­‘åº•æˆåŠŸ'],
                ['å¤šå¤´å­•çº¿', 'ä¹°å…¥', 'é•¿é˜´åŒ…å«å°Kçº¿ï¼Œåº•éƒ¨å­•è‚²ï¼Œå˜ç›˜åœ¨å³'],
                ['çº¢ä¸‰å…µ', 'ä¹°å…¥', 'è¿ç»­ä¸‰å¤©é˜³çº¿ç¨³æ­¥æ¨å‡'],
                ['ä¸Šå‡ä¸‰æ³•', 'ä¹°å…¥', 'å¤§é˜³åæ¥ä¸‰å°é˜´ä¸ç ´ä½ï¼Œå†æ¥å¤§é˜³'],
                ['å¤šæ–¹ç‚®', 'ä¹°å…¥', 'é˜³é˜´é˜³ç»„åˆï¼Œæ´—ç›˜ç»“æŸï¼Œå†æ¬¡ä¸Šæ”»'],
                ['å‘ä¸Šç¼ºå£', 'ä¹°å…¥', 'å‘ä¸Šè·³ç©ºä¸å›è¡¥ï¼Œä¸»åŠ›å¼ºåŠ¿ç‰¹å¾'],
                ['ä¸€é˜³ç©¿ä¸‰çº¿', 'ä¹°å…¥', 'å¤§é˜³çº¿åŒæ—¶çªç ´5/10/20å‡çº¿'],
                ['å€é‡è¿‡å·¦å³°', 'ä¹°å…¥', 'æˆäº¤é‡ç¿»å€ä¸”ä»·æ ¼çªç ´å‰æœŸé«˜ç‚¹'],
                ['é‡‘èœ˜è››', 'ä¹°å…¥', 'å‡çº¿ç²˜åˆåæ”¾é‡å‘ä¸Šå‘æ•£'],
                ['ä»™äººæŒ‡è·¯', 'ä¹°å…¥', 'ä»Šæ—¥å¤§é˜³çº¿çªç ´æ˜¨æ—¥çš„é•¿ä¸Šå½±çº¿'],
                ['æ—­æ—¥ä¸œå‡', 'ä¹°å…¥', 'å¤§é˜´çº¿åé«˜å¼€é«˜èµ°ï¼ŒåŒ…å«å‰ä¸€æ—¥é˜´çº¿'],
                ['å²›å½¢åè½¬(åº•)', 'ä¹°å…¥', 'ä¸‹è·Œç¼ºå£+ç›˜æ•´+ä¸Šæ¶¨ç¼ºå£ï¼Œè¶…å¼ºåè½¬'],
                ['è¸¢è„šçº¿', 'ä¹°å…¥', 'å¤§é˜´çº¿åç›´æ¥é«˜å¼€é«˜èµ°ï¼Œä¸»åŠ›æš´åŠ›åè½¬'],
                ['èœ»èœ“ç‚¹æ°´', 'ä¹°å…¥', 'è‚¡ä»·å›è¸©å‡çº¿åç«‹å³å¼¹èµ·'],
                ['é»„æ˜ä¹‹æ˜Ÿ', 'å–å‡º', 'é¡¶éƒ¨ä¸‰æ—¥ç»„åˆï¼šé˜³çº¿+æ˜Ÿçº¿+é˜´çº¿'],
                ['ä¹Œäº‘ç›–é¡¶', 'å–å‡º', 'å¤§é˜³åæ¥å¤§é˜´ï¼Œåƒæ‰ä¸€åŠæ¶¨å¹…'],
                ['é˜´åŒ…é˜³', 'å–å‡º', 'ç©ºå¤´åå™¬ï¼Œé˜´çº¿åŒ…ä½é˜³çº¿'],
                ['ä¸‰åªä¹Œé¸¦', 'å–å‡º', 'è¿ç»­ä¸‰æ ¹é˜´çº¿æ€è·Œ'],
                ['å°„å‡»ä¹‹æ˜Ÿ', 'å–å‡º', 'é«˜ä½é•¿ä¸Šå½±çº¿ï¼Œå†²é«˜å›è½'],
                ['åŠé¢ˆçº¿', 'å–å‡º', 'é«˜ä½é•¿ä¸‹å½±çº¿ï¼Œä¸»åŠ›è¯±å¤š'],
                ['æ–­å¤´é“¡åˆ€', 'å–å‡º', 'ä¸€é˜´æ–­å¤šçº¿ï¼Œè¶‹åŠ¿å´©å¡Œ'],
                ['å‘ä¸‹ç¼ºå£', 'å–å‡º', 'å‘ä¸‹è·³ç©ºä¸å›è¡¥ï¼Œæå¼±åŠ¿'],
                ['å€¾ç›†å¤§é›¨', 'å–å‡º', 'ä½å¼€ä½èµ°å¤§é˜´çº¿ï¼Œåæ²¡å‰æ—¥æ¶¨å¹…'],
                ['ç©ºå¤´å­•çº¿', 'å–å‡º', 'é«˜ä½é•¿é˜³åŒ…å«å°Kçº¿ï¼Œæ»æ¶¨ä¿¡å·'],
                ['å²›å½¢åè½¬(é¡¶)', 'å–å‡º', 'ä¸Šæ¶¨ç¼ºå£+ç›˜æ•´+ä¸‹è·Œç¼ºå£ï¼Œè§é¡¶ä¿¡å·'],
                ['å¢“ç¢‘çº¿', 'å–å‡º', 'é«˜ä½Tå­—çº¿ï¼Œå¤šå¤´åŠ›ç«­']
            ]
            pd.DataFrame(patterns_desc[1:], columns=patterns_desc[0]).to_excel(writer, sheet_name='å½¢æ€å›¾è§£', index=False)

            indicators_desc = [
                ['æŒ‡æ ‡åç§°', 'å®æˆ˜å«ä¹‰', 'åˆ¤æ–­æ ‡å‡†'],
                ['é‡æ¯”', 'é‡èƒ½å˜åŒ–', '>1.5ä¸ºæ”¾é‡ï¼›0.5-1.0ä¸ºç¼©é‡(é”ç­¹)'],
                ['CMF', 'èµ„é‡‘æµ', 'è¿ç»­ä¸ºæ­£ä¸”é€’å¢ï¼Œè¯´æ˜ä¸»åŠ›æŒç»­æ‹¿è´§'],
                ['ADX', 'è¶‹åŠ¿å¼ºåº¦', '>25è¡¨ç¤ºè¶‹åŠ¿å¼ºåŠ²ï¼›<20è¡¨ç¤ºéœ‡è¡(è§‚æœ›)'],
                ['RSI', 'å¼ºå¼±æŒ‡æ ‡', '50-80ä¸ºå¼ºåŠ¿åŒºï¼Œ>80è¿‡çƒ­ï¼Œ<20è¶…å–'],
                ['CCI', 'é¡ºåŠ¿æŒ‡æ ‡', '>100è¡¨ç¤ºè¿›å…¥åŠ é€ŸåŒºï¼Œ<-100è¡¨ç¤ºè¶…è·Œ'],
                ['Jå€¼(KDJ)', 'è¶…ä¹°è¶…å–', '<0ä¸ºè¶…è·Œåå¼¹æœºä¼šï¼›>100ä¸ºé’åŒ–é£é™©'],
                ['ATR', 'çœŸå®æ³¢å¹…', 'ç”¨äºè®¡ç®—åŠ¨æ€æ­¢æŸä½ï¼Œæ³¢åŠ¨è¶Šå¤§æ­¢æŸè¶Šå®½'],
                ['BIAS', 'ä¹–ç¦»ç‡', 'æ­£å€¼è¿‡å¤§è¦å›è°ƒï¼Œè´Ÿå€¼è¿‡å¤§æœ‰åå¼¹'],
                ['å¸ƒæ—å¸¦å®½', 'å˜ç›˜å‰å…†', 'æ•°å€¼è¶Šå°(<0.10)è¯´æ˜ç­¹ç è¶Šé›†ä¸­ï¼Œå³å°†å˜ç›˜'],
                ['PE(å¸‚ç›ˆç‡)', 'ä¼°å€¼', '0<PE<20ä¸ºä½ä¼°ï¼ŒPE<0ä¸ºäºæŸ'],
                ['PB(å¸‚å‡€ç‡)', 'èµ„äº§ä»·æ ¼', 'PB>10é£é™©è¾ƒé«˜'],
                ['è·åˆ©ç›˜%', 'ç­¹ç åˆ†å¸ƒ', '>90%æ„å‘³ä¸Šæ–¹æ— å¥—ç‰¢ä½†æœ‰æŠ›å‹ï¼›<10%ä¸ºè¶…è·Œ']
            ]
            pd.DataFrame(indicators_desc[1:], columns=indicators_desc[0]).to_excel(writer, sheet_name='æŒ‡æ ‡è¯´æ˜ä¹¦', index=False)
            
        return output.getvalue(), filename

# ================= 8. Streamlit å‰ç«¯äº¤äº’å±‚ =================

st.title("ğŸš€ Alpha Galaxy Ultimate (æé€Ÿç‰ˆ)")
st.markdown("### å…¨ç»´æ‰«æ | å¤šçº¿ç¨‹å¼•æ“ | æ™ºèƒ½ç¼“å­˜")

# 1. è¾“å…¥åŒº
col_input, col_btn = st.columns([3, 1])
with col_input:
    stock_code = st.text_input("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç  (å¦‚ 600519)", value="", placeholder="æ”¯æŒAè‚¡/åŒ—äº¤æ‰€")

with col_btn:
    st.write("") # å ä½ç¬¦
    st.write("") # å ä½ç¬¦
    run_btn = st.button("â–¶ï¸ å¼€å§‹æ‰«æ", type="primary", use_container_width=True)

# 2. æ‰§è¡Œé€»è¾‘
if run_btn:
    if not stock_code:
        st.error("âš ï¸ è¯·å…ˆè¾“å…¥è‚¡ç¥¨ä»£ç ")
    else:
        with st.spinner(f"æ­£åœ¨å…¨ç»´æ‰«æ {stock_code} (å·²å¯ç”¨å¤šçº¿ç¨‹åŠ é€Ÿ)..."):
            app = AlphaGalaxyUltimate(stock_code)
            
            excel_data, file_name = app.generate_excel_in_memory()
            
            if excel_data:
                st.success(f"âœ… [{app.data['spot'].get('åç§°', stock_code)}] åˆ†æå®Œæˆï¼")
                
                # --- å¤§å±çœ‹æ¿å±•ç¤º ---
                r = app.report
                
                # ç¬¬ä¸€è¡Œï¼šæ ¸å¿ƒç»“è®º
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("æœ€ç»ˆå»ºè®®", r['verdict'], delta_color="normal" if r['verdict']=="è§‚æœ›" else "inverse")
                c2.metric("ç»¼åˆè¯„åˆ†", r['score'])
                c3.metric("å»ºè®®ä»“ä½", f"{r['kelly_pos']}%")
                c4.metric("é£é™©ç­‰çº§", r['risk_level'])
                
                st.divider()
                
                # ç¬¬äºŒè¡Œï¼šç‚¹ä½ä¸é€»è¾‘
                c_left, c_right = st.columns([1, 1])
                with c_left:
                    st.subheader("ğŸ¯ å…³é”®ç‚¹ä½")
                    levels_df = pd.DataFrame(app.levels, columns=["ç±»å‹", "ä»·æ ¼", "è¯´æ˜"])
                    st.dataframe(levels_df, use_container_width=True, hide_index=True)
                
                with c_right:
                    st.subheader("ğŸ’¡ å†³ç­–é€»è¾‘")
                    for logic in r['logic']:
                        st.write(f"- {logic}")
                    if r['patterns_bull']: st.success(f"å¤šå¤´å½¢æ€: {', '.join(r['patterns_bull'])}")
                    if r['patterns_bear']: st.error(f"ç©ºå¤´å½¢æ€: {', '.join(r['patterns_bear'])}")

                # --- ä¸‹è½½æŒ‰é’® ---
                st.divider()
                st.download_button(
                    label=f"ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥å‘Š: {file_name}",
                    data=excel_data,
                    file_name=file_name,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary",
                    use_container_width=True
                )